{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3778cad2",
      "metadata": {
        "id": "3778cad2"
      },
      "source": [
        "# Ćwiczenia 4 - Regularyzacja\n",
        "\n",
        "## Early stopping\n",
        "Polega na zatrzymaniu uczenia w momencie kiedy wybrana metryka przestała się poprawiać dla danych walidacyjnych.\n",
        "Keras pozwala na zaimplementowac tę metodę jako callback, który można podać jako parametr w metodzie `fit`, np.:\n",
        "\n",
        "```python\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=2, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(..., callbacks=[early_stopping])\n",
        "```\n",
        "\n",
        "## Regularyzacja L1/L2\n",
        "\n",
        "Do funkcji błędu dodawany jest dodatkowy termin penalizujący zbyt duże wagi:\n",
        "\n",
        "$$ \\tilde{J}(W) = J(W) + \\lambda \\sum_i w_i^2 $$\n",
        "$$ \\tilde{J}(W) = J(W) + \\lambda \\sum_i |w_i| $$\n",
        "\n",
        "Aby zastosować tę metodę dla warstwy, należy ustawić parametr `kernel_regularizer`, np:\n",
        "\n",
        "```python\n",
        "tf.keras.layers.Dense(..., kernel_regularizer=tf.keras.regularizers.l2(0.1))\n",
        "```\n",
        "\n",
        "## Regularyzacja Dropout\n",
        "\n",
        "Regularyzacja Dropout polega na losowym wyłączaniu pewnej części neuronów w sieci podczas uczenia.\n",
        "Metodę tę można zaimplementowac dodając warstwę `Dropout` bezpośrednio po regularyzowanej warstwie.\n",
        "\n",
        "## Augmentacja danych\n",
        "\n",
        "Polega na wprowadzaniu drobnych zmian w danych treningowych.\n",
        "Technika ta jest szczególnie przydatna w przetwarzaniu obrazów. Różne transformacje można zastosować dodając odpowiednie warstwy na wejściu sieci, np.: `RandomRotation`, `RandomZoom`, `RandomBrightness`. Pełna lista dostępncyh transformacji: https://keras.io/api/layers/preprocessing_layers/image_augmentation/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0c9215",
      "metadata": {
        "id": "8f0c9215"
      },
      "source": [
        "## Zadania\n",
        "1. Wczytaj zbiór `imdb` z Ćwiczeń 03. Zastosuj sieć wielowarstwową do klasyfikacji zbioru (możesz wykorzystać sieć z przykładu). Stwórz wykres pokazujący błąd dla danych treningowych/walidacyjnych w kolejnych epokach i zaobserwuj efekt przetrenowania. Następnie uruchom sieć ponownie, stosując Early Stopping aby zatrzymać uczenie w momencie, kiedy funkcja straty przestanie się zminiejszać dla danych walidacyjnych.\n",
        "2. Dodaj do warstw ukrytych sieci z Zadania 1. regularyzację L1/L2. Dobierz odpowiednie wartości współczynnika regularyzacji. Trenuj sieci bez stosowania Early Stopping. Stwórz wykresy krzywych uczenia i porównaj działanie regularyzowanych sieci z siecią z Zadania 1.\n",
        "3. Dodaj do warstw ukrytych sieci z Zadania 1. regularyzację Dropout. Dobierz odpowiedni parametr `rate`. Stwórz wykres krzywej uczenia i porównaj działanie sieci stosującej Dropout z siecią z Zadania 1.\n",
        "4. (opcjonalne) Dodaj do sieci klasyfikującej zbiór CIFAR-10 stworzonej na wcześniejszych zajęciach augmentację obrazów. Bezpośrednio po warstwie `Input` i przed warstwą `Flatten` dodaj wybrane transformacje."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "X1e5NmcYzWSL"
      },
      "id": "X1e5NmcYzWSL",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(train_data + test_data)\n",
        "X_train_full = mlb.transform(train_data)\n",
        "y_train_full = train_labels\n",
        "X_test = mlb.transform(test_data)\n",
        "y_test = test_labels\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.33, random_state=911)"
      ],
      "metadata": {
        "id": "17My1Rf2zYL_"
      },
      "id": "17My1Rf2zYL_",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Yi6AWkJDzp6T"
      },
      "id": "Yi6AWkJDzp6T",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=20)"
      ],
      "metadata": {
        "id": "IEZWfmE6z4aI",
        "outputId": "005c2f47-6848-40f4-c781-6f2b578485d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IEZWfmE6z4aI",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7096 - loss: 0.5498 - val_accuracy: 0.7784 - val_loss: 0.4976\n",
            "Epoch 2/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8803 - loss: 0.2950 - val_accuracy: 0.8588 - val_loss: 0.3384\n",
            "Epoch 3/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.2351 - val_accuracy: 0.8250 - val_loss: 0.4413\n",
            "Epoch 4/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9258 - loss: 0.1896 - val_accuracy: 0.8739 - val_loss: 0.2988\n",
            "Epoch 5/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.1540 - val_accuracy: 0.8755 - val_loss: 0.3159\n",
            "Epoch 6/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9484 - loss: 0.1369 - val_accuracy: 0.8773 - val_loss: 0.3195\n",
            "Epoch 7/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9598 - loss: 0.1091 - val_accuracy: 0.8725 - val_loss: 0.3667\n",
            "Epoch 8/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9657 - loss: 0.0963 - val_accuracy: 0.8233 - val_loss: 0.5791\n",
            "Epoch 9/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.0746 - val_accuracy: 0.8691 - val_loss: 0.4094\n",
            "Epoch 10/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0553 - val_accuracy: 0.8725 - val_loss: 0.4720\n",
            "Epoch 11/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0445 - val_accuracy: 0.8715 - val_loss: 0.5023\n",
            "Epoch 12/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0307 - val_accuracy: 0.8714 - val_loss: 0.5245\n",
            "Epoch 13/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0195 - val_accuracy: 0.8292 - val_loss: 0.8456\n",
            "Epoch 14/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0183 - val_accuracy: 0.8675 - val_loss: 0.6388\n",
            "Epoch 15/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0081 - val_accuracy: 0.8732 - val_loss: 0.6624\n",
            "Epoch 16/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0052 - val_accuracy: 0.8732 - val_loss: 0.6762\n",
            "Epoch 17/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0039 - val_accuracy: 0.8672 - val_loss: 0.7149\n",
            "Epoch 18/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.8726 - val_loss: 0.7257\n",
            "Epoch 19/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.8698 - val_loss: 0.7550\n",
            "Epoch 20/20\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.8699 - val_loss: 0.7731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "print(history.history.keys())\n",
        "epoch = range(len(loss))\n",
        "\n",
        "ax1.plot(epoch, loss, label=\"Training Loss\")\n",
        "ax1.plot(epoch, val_loss, label=\"Validation Loss\")\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(epoch, accuracy, label=\"Training Accuracy\")\n",
        "ax2.plot(epoch, val_accuracy, label=\"Validation Accuracy\")\n",
        "ax2.set_xlabel(\"Epoch\")\n",
        "ax2.set_ylabel(\"Loss\")\n",
        "ax2.legend()"
      ],
      "metadata": {
        "id": "GrJNyCWIz8PV"
      },
      "id": "GrJNyCWIz8PV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}